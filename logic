from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import AzureChatOpenAI
import os
import json

def build_intent_entity_extractor():
    """
    Single LLM call to classify intent and extract entities.
    Returns JSON with keys:
    - intent: string
    - standard_names: list
    - standard_versions: list
    - release_date: string or null
    """
    llm = AzureChatOpenAI(
        api_key=os.getenv("OPENAI_API_KEY"),
        api_version=os.getenv("OPENAI_VERSION"),
        azure_deployment=os.getenv("OPENAI_DEPLOYMENT"),
        azure_endpoint=os.getenv("OPENAI_BASE"),
        temperature=0
    )

    system_prompt = """You are a telecom assistant.
Your task:
1. Determine the user intent. Possible intents:
- analyze_latest
- compare_versions
- compare_standards
- compare_standard_versions
- explain_features
- latest_standard
If none apply, return "none".

2. Extract entities from the query:
- standard_names: list of all standard names mentioned
- standard_versions: list of all versions mentioned, normalized with capital V
- release_date: release date if mentioned, else null

Return a single JSON object with keys: intent, standard_names, standard_versions, release_date.
Only return valid JSON."""

    prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        ("human", "{query}")
    ])

    return prompt | llm

# Usage
intent_entity_extractor = build_intent_entity_extractor()
query = "Compare versions 3.0.0 and v6.0.89 for KE and 3GPP TR 23.700-67"
response = intent_entity_extractor.invoke({"query": query})

try:
    data = json.loads(response.content)
except:
    data = {"intent": "none", "standard_names": [], "standard_versions": [], "release_date": None}

print(data)
