from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from agents.utils.rag_pipeline import (
    build_intent_classifier,
    build_entity_extractor,
    get_full_docs,
    build_rag_chain
)
from utils.functions import insert_chat_history, get_chat_history

router = APIRouter()

# Build chains once
intent_classifier = build_intent_classifier()
entity_extractor = build_entity_extractor()
rag_chain = build_rag_chain()

# -------------------
# Request/Response Models
# -------------------
class ChatRequest(BaseModel):
    question: str

class ChatResponse(BaseModel):
    answer: str

class ChatHistoryItem(BaseModel):
    id: int
    timestamp: str
    question: str
    answer: str

# -------------------
# Chat Endpoint
# -------------------
@router.post("/chat/", response_model=ChatResponse)
async def chat(request: ChatRequest):
    try:
        query = request.question

        # 1️⃣ Classify Intent
        intent_response = intent_classifier.invoke({"query": query})
        intent = intent_response.content.strip()
        
        # 2️⃣ Extract Entities (standards, versions)
        entity_response = entity_extractor.invoke({"query": query})
        entities = entity_response.content
        # Convert JSON string to dict safely
        import json
        try:
            entities = json.loads(entities)
        except:
            entities = {"standard_names": [], "standard_versions": [], "release_date": None}

        standard_names = entities.get("standard_names", [])
        standard_versions = entities.get("standard_versions", [])
        release_date = entities.get("release_date", None)

        # 3️⃣ Determine full documents to retrieve
        all_text_chunks = []

        if intent != "none" and standard_names:
            # Loop over all standard_name/version pairs
            for i, std_name in enumerate(standard_names):
                version = standard_versions[i] if i < len(standard_versions) else None
                filters = {"standard_name": std_name}
                if version:
                    filters["standard_version"] = version
                docs = get_full_docs(filters)
                for doc, meta in docs:
                    all_text_chunks.append(doc)
        
        # If no docs found or intent is none, fallback to general RAG
        if not all_text_chunks or intent == "none":
            result = rag_chain.invoke({"input": query})
            answer = result["answer"]
        else:
            # Concatenate all chunks into one context
            context_text = "\n\n".join(all_text_chunks)
            
            # Build a simple prompt for summarization / analysis
            analysis_prompt = f"""
You are a telecom standards assistant. Use the following context to answer the user query:
Context:
{context_text}

Question: {query}
Answer concisely and accurately:
"""
            result = rag_chain.invoke({"input": analysis_prompt})
            answer = result["answer"]

        # 4️⃣ Insert chat history
        insert_chat_history(query, answer)

        return ChatResponse(answer=answer)

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# -------------------
# Chat History Endpoint
# -------------------
@router.get("/chat-history/", response_model=list[ChatHistoryItem])
async def chat_history():
    rows = get_chat_history()
    return [
        ChatHistoryItem(
            id=row[0],
            timestamp=row[1],
            question=row[2],
            answer=row[3]
        )
        for row in rows
    ]
