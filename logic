from langchain.text_splitter import RecursiveCharacterTextSplitter

def extract_features_from_doc(docs, user_question):
    """
    Takes full documents (list of (chunk, metadata)) and user question.
    Returns LLM-extracted features from the full document.
    Handles long docs by chunking + summarizing.
    """
    # 1️⃣ Concatenate all chunks
    full_text = "\n\n".join([chunk for chunk, _meta in docs])

    # 2️⃣ Split into manageable chunks for LLM
    splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=200)
    text_chunks = splitter.split_text(full_text)

    llm = AzureChatOpenAI(
        api_key=OPENAI_API_KEY,
        api_version=OPENAI_API_VERSION,
        azure_deployment=OPENAI_DEPLOYMENT,
        azure_endpoint=OPENAI_DEPLOYMENT_ENDPOINT,
        temperature=0
    )

    # 3️⃣ Summarize each chunk
    chunk_summaries = []
    for chunk in text_chunks:
        prompt = f"""
        Summarize the key points of this document chunk for telecom standards analysis:

        {chunk}
        """
        res = llm.invoke(prompt)
        chunk_summaries.append(res.content)

    # 4️⃣ Combine all summaries
    combined_summary = "\n\n".join(chunk_summaries)

    # 5️⃣ Ask LLM to extract features from combined summary
    final_prompt = f"""
    The following is a summarized version of the full document:
    {combined_summary}

    Extract the key FEATURES of the standard.
    If explicit features are not mentioned, infer the most important aspects.
    """
    final_res = llm.invoke(final_prompt)
    return final_res.content
